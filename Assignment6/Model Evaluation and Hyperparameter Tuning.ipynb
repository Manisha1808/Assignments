{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcf13ff-a11a-49c6-99e4-21cbe6f492ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4539ce08-37c6-44c4-8376-4e3e4cf55020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07285e4b-c8f3-4d62-bfc2-20ae1814ad39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Logistic Regression  0.956140   0.945946  0.985915  0.965517\n",
      "1        Random Forest  0.956140   0.958333  0.971831  0.965035\n",
      "2                  SVM  0.947368   0.922078  1.000000  0.959459\n",
      "3          Naive Bayes  0.973684   0.959459  1.000000  0.979310\n",
      "4        Decision Tree  0.938596   0.944444  0.957746  0.951049\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c93c13-443c-4b19-882e-4d169acbb264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from GridSearchCV: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0064729f-7a23-4cf6-8b38-f922abb67ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from RandomizedSearchCV: {'C': np.float64(3.1424224295953773), 'gamma': 'auto', 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist = {\n",
    "    'C': uniform(0.1, 10),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_dist, n_iter=10, cv=5, scoring='f1', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
    "best_svm = random_search.best_estimator_\n",
    "\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d0f7ed-7f7c-4b90-9228-37820e85551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Comparison after Tuning:\n",
      "                    Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Random Forest (Tuned)  0.964912   0.958904  0.985915  0.972222\n",
      "1            SVM (Tuned)  0.956140   0.945946  0.985915  0.965517\n"
     ]
    }
   ],
   "source": [
    "final_results = []\n",
    "\n",
    "for name, model in [(\"Random Forest (Tuned)\", best_rf), (\"SVM (Tuned)\", best_svm)]:\n",
    "    y_pred = model.predict(X_test)\n",
    "    final_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(final_results)\n",
    "print(\"\\nFinal Comparison after Tuning:\\n\", final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cadb3f-111d-49ae-aac8-f23d53fba30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f513bc-0285-4acf-85f0-f00a5cc353eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5914a0-cbee-4332-bfcc-4f8db540a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b12df-6eb5-421e-94d1-2082a7c4a707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
